{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4878048780487805,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016260162601626018,
      "grad_norm": 4.102899074554443,
      "learning_rate": 0.0001989159891598916,
      "loss": 2.4242,
      "step": 10
    },
    {
      "epoch": 0.032520325203252036,
      "grad_norm": 2.351649284362793,
      "learning_rate": 0.00019783197831978321,
      "loss": 1.5107,
      "step": 20
    },
    {
      "epoch": 0.04878048780487805,
      "grad_norm": 3.220911741256714,
      "learning_rate": 0.00019674796747967482,
      "loss": 1.1754,
      "step": 30
    },
    {
      "epoch": 0.06504065040650407,
      "grad_norm": 4.484182357788086,
      "learning_rate": 0.0001956639566395664,
      "loss": 0.857,
      "step": 40
    },
    {
      "epoch": 0.08130081300813008,
      "grad_norm": 4.215541839599609,
      "learning_rate": 0.000194579945799458,
      "loss": 0.5763,
      "step": 50
    },
    {
      "epoch": 0.0975609756097561,
      "grad_norm": 3.953232526779175,
      "learning_rate": 0.00019349593495934962,
      "loss": 0.42,
      "step": 60
    },
    {
      "epoch": 0.11382113821138211,
      "grad_norm": 3.713036298751831,
      "learning_rate": 0.0001924119241192412,
      "loss": 0.2877,
      "step": 70
    },
    {
      "epoch": 0.13008130081300814,
      "grad_norm": 2.6591408252716064,
      "learning_rate": 0.0001913279132791328,
      "loss": 0.1769,
      "step": 80
    },
    {
      "epoch": 0.14634146341463414,
      "grad_norm": 4.053531646728516,
      "learning_rate": 0.0001902439024390244,
      "loss": 0.144,
      "step": 90
    },
    {
      "epoch": 0.16260162601626016,
      "grad_norm": 2.823812246322632,
      "learning_rate": 0.000189159891598916,
      "loss": 0.1395,
      "step": 100
    },
    {
      "epoch": 0.17886178861788618,
      "grad_norm": 2.3399741649627686,
      "learning_rate": 0.0001880758807588076,
      "loss": 0.1384,
      "step": 110
    },
    {
      "epoch": 0.1951219512195122,
      "grad_norm": 2.393558979034424,
      "learning_rate": 0.00018699186991869918,
      "loss": 0.1344,
      "step": 120
    },
    {
      "epoch": 0.21138211382113822,
      "grad_norm": 2.055365800857544,
      "learning_rate": 0.00018590785907859078,
      "loss": 0.122,
      "step": 130
    },
    {
      "epoch": 0.22764227642276422,
      "grad_norm": 1.8710949420928955,
      "learning_rate": 0.0001848238482384824,
      "loss": 0.1284,
      "step": 140
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 2.704667806625366,
      "learning_rate": 0.000183739837398374,
      "loss": 0.1335,
      "step": 150
    },
    {
      "epoch": 0.2601626016260163,
      "grad_norm": 2.3714263439178467,
      "learning_rate": 0.0001826558265582656,
      "loss": 0.1175,
      "step": 160
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 2.2169430255889893,
      "learning_rate": 0.0001815718157181572,
      "loss": 0.118,
      "step": 170
    },
    {
      "epoch": 0.2926829268292683,
      "grad_norm": 1.9993646144866943,
      "learning_rate": 0.0001804878048780488,
      "loss": 0.1207,
      "step": 180
    },
    {
      "epoch": 0.3089430894308943,
      "grad_norm": 1.406777024269104,
      "learning_rate": 0.0001794037940379404,
      "loss": 0.1136,
      "step": 190
    },
    {
      "epoch": 0.3252032520325203,
      "grad_norm": 1.347113847732544,
      "learning_rate": 0.00017831978319783197,
      "loss": 0.1162,
      "step": 200
    },
    {
      "epoch": 0.34146341463414637,
      "grad_norm": NaN,
      "learning_rate": 0.0001773441734417344,
      "loss": 0.1208,
      "step": 210
    },
    {
      "epoch": 0.35772357723577236,
      "grad_norm": 1.4314002990722656,
      "learning_rate": 0.00017626016260162603,
      "loss": 0.1168,
      "step": 220
    },
    {
      "epoch": 0.37398373983739835,
      "grad_norm": 1.9479658603668213,
      "learning_rate": 0.00017517615176151764,
      "loss": 0.1105,
      "step": 230
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 1.7132841348648071,
      "learning_rate": 0.0001740921409214092,
      "loss": 0.1095,
      "step": 240
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 1.1401349306106567,
      "learning_rate": 0.00017300813008130081,
      "loss": 0.1109,
      "step": 250
    },
    {
      "epoch": 0.42276422764227645,
      "grad_norm": 1.4661171436309814,
      "learning_rate": 0.00017192411924119242,
      "loss": 0.1079,
      "step": 260
    },
    {
      "epoch": 0.43902439024390244,
      "grad_norm": 0.8936856985092163,
      "learning_rate": 0.00017084010840108402,
      "loss": 0.1053,
      "step": 270
    },
    {
      "epoch": 0.45528455284552843,
      "grad_norm": 1.0141737461090088,
      "learning_rate": 0.00016975609756097562,
      "loss": 0.1056,
      "step": 280
    },
    {
      "epoch": 0.4715447154471545,
      "grad_norm": 0.9100502729415894,
      "learning_rate": 0.0001686720867208672,
      "loss": 0.0995,
      "step": 290
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 2.1096041202545166,
      "learning_rate": 0.00016758807588075883,
      "loss": 0.105,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 1845,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.5357464379392e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
